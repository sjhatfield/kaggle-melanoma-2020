{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing EfficientNet Locally Before Transferring To The Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.data.prepare_data import *\n",
    "from src.models.model import *\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2718)\n",
    "np.random.seed(2718)\n",
    "torch.manual_seed(2718)\n",
    "SEED = 2718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/internal/train.csv\")\n",
    "test = pd.read_csv(\"../data/internal/test.csv\")\n",
    "sub = pd.read_csv(\"../data/internal/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has enough parameters that it is not feasible to train a model with larger than 64x64 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'INPUT_DIR'      : '',\n",
    "    'MODEL'          : 'efficientnet-b0',\n",
    "    'SIZE'           : 128,\n",
    "    'BATCH_SIZE'     : 32,\n",
    "    'NUM_FOLDS'      : 3,\n",
    "    'NUM_EPOCHS'     : 20,\n",
    "    'FREEZED_EPOCHS' : 3,\n",
    "    'LEARNING_RATE'  : 1e-3,\n",
    "    'EARLY_STOPPING' : 10,\n",
    "    'UNIFORM_AUGMENT': True,\n",
    "    'TTA'            : 3,\n",
    "    'NUM_WORKERS'    : 16,\n",
    "    'DEVICE'         : 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "---- fold: 3 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [09:05<00:00,  1.25it/s]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss_train: 0.5630, loss_valid: 0.3856, auc_valid: 0.8116, saved: True, 750.1975sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [08:55<00:00,  1.27it/s]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, loss_train: 0.5528, loss_valid: 0.3863, auc_valid: 0.8058, saved: False, 752.5936sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [08:58<00:00,  1.27it/s]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss_train: 0.5422, loss_valid: 0.3268, auc_valid: 0.8085, saved: False, 755.3972sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [29:30<00:00,  2.60s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, loss_train: 0.4319, loss_valid: 0.2391, auc_valid: 0.8619, saved: True, 1979.8363sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [28:41<00:00,  2.52s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, loss_train: 0.2988, loss_valid: 0.1603, auc_valid: 0.8809, saved: True, 1941.2941sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [29:09<00:00,  2.57s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, loss_train: 0.2343, loss_valid: 0.1641, auc_valid: 0.8725, saved: False, 1959.2246sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [28:50<00:00,  2.54s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, loss_train: 0.1852, loss_valid: 0.1281, auc_valid: 0.8593, saved: False, 1940.5230sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [29:10<00:00,  2.57s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, loss_train: 0.1592, loss_valid: 0.1280, auc_valid: 0.8549, saved: False, 1958.1935sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [28:37<00:00,  2.52s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, loss_train: 0.1336, loss_valid: 0.1069, auc_valid: 0.8676, saved: False, 1900.0267sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [26:00<00:00,  2.29s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss_train: 0.1160, loss_valid: 0.1101, auc_valid: 0.8703, saved: False, 1740.4265sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [25:18<00:00,  2.23s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, loss_train: 0.1127, loss_valid: 0.1080, auc_valid: 0.8697, saved: False, 1696.6169sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [25:22<00:00,  2.23s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, loss_train: 0.1077, loss_valid: 0.1092, auc_valid: 0.8661, saved: False, 1700.8553sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [26:15<00:00,  2.31s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, loss_train: 0.1102, loss_valid: 0.1088, auc_valid: 0.8668, saved: False, 1756.1763sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [25:28<00:00,  2.24s/it]\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, loss_train: 0.1078, loss_valid: 0.1085, auc_valid: 0.8658, saved: False, 1707.2401sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [25:27<00:00,  2.24s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, loss_train: 0.1033, loss_valid: 0.1081, auc_valid: 0.8660, saved: False, 1717.6983sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:42<00:00, 194.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold took 24838.69\n",
      "total time: 24838.7177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "predictions = pd.DataFrame()\n",
    "transform = ImageTransform(config['SIZE'], config['UNIFORM_AUGMENT'])\n",
    "\n",
    "skf = KFold(n_splits=config['NUM_FOLDS'], shuffle=True, random_state=SEED)\n",
    "for i, (idxT,idxV) in enumerate(skf.split(np.arange(15))):\n",
    "    if i == 2:\n",
    "        t_fold = time.time()\n",
    "        tr = train.loc[train.tfrecord.isin(idxT)]\n",
    "        va = train.loc[train.tfrecord.isin(idxV)]\n",
    "        tr.reset_index(drop=True, inplace=True)\n",
    "        va.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # create datasets\n",
    "        dataset_train = MelanomaDataset(\"../data/internal/train\", tr, transform=transform, phase='train')\n",
    "        dataset_valid = MelanomaDataset(\"../data/internal/train\", va, transform=transform, phase='valid')\n",
    "\n",
    "        # load a pretrained model\n",
    "        net = load_model(config['MODEL'], 2)\n",
    "\n",
    "        # define a loss function\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # define an optimizer\n",
    "        optimizer = optim.Adam(net.parameters(), lr=config['LEARNING_RATE'])\n",
    "\n",
    "        # define a scheduler\n",
    "        scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=2, factor=0.2)\n",
    "\n",
    "        # create a sampler\n",
    "        sampler = create_weighted_random_sampler(tr)\n",
    "\n",
    "        # train the network\n",
    "        print(f\"---- fold: {i + 1} ------------\")\n",
    "        train_model(\n",
    "            f\"{config['MODEL']}_{i + 1}\",\n",
    "            dataset_train,\n",
    "            dataset_valid,\n",
    "            config['BATCH_SIZE'],\n",
    "            net,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            config['NUM_EPOCHS'],\n",
    "            config['FREEZED_EPOCHS'],\n",
    "            config['INPUT_DIR'],\n",
    "            config['NUM_WORKERS'],\n",
    "            sampler,\n",
    "            config['DEVICE'],\n",
    "            config['EARLY_STOPPING']\n",
    "        )\n",
    "\n",
    "        # predict on test dataset\n",
    "        test['target'] = 0\n",
    "        dataset_test = MelanomaDataset(\"../data/internal/test\", test, transform=transform, phase='test')\n",
    "        predictions = get_predictions(dataset_test, \n",
    "                                      config[\"BATCH_SIZE\"], \n",
    "                                      net, \n",
    "                                      config[\"TTA\"], \n",
    "                                      predictions, \n",
    "                                      config[\"DEVICE\"])\n",
    "        predictions.to_csv(f'../submissions/{config[\"MODEL\"]}_fold{i+1}.csv')\n",
    "        print(f\"fold took {round(time.time() - t_fold, 2)}\")\n",
    "    \n",
    "# output\n",
    "sub['target'] = predictions.mean(axis=1)\n",
    "sub.to_csv(f\"../submissions/submission{config['MODEL']}.csv\", index=False)\n",
    "print(f\"total time: {round(time.time() - t, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
