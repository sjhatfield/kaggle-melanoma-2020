{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling the Resnet18 Model and XGBoost on Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "import torch\n",
    "from src.data.prepare_data import *\n",
    "from src.models.model import *\n",
    "from src.data.prepare_data import format_tabular\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a different seed than during training to create different folds\n",
    "SEED = 3142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/internal/train.csv\")\n",
    "test = pd.read_csv(\"../data/internal/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = format_tabular(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:53<05:46, 173.20s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:37<02:50, 170.47s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:22<00:00, 167.40s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:26, 163.34s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:28<02:43, 163.75s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:12<00:00, 164.12s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.73s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:29<02:44, 164.25s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:13<00:00, 164.67s/it]\u001b[A\n",
      " 11%|█         | 1/9 [24:49<3:18:37, 1489.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:45<05:30, 165.00s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:29<02:44, 164.93s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:14<00:00, 164.78s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:44<05:28, 164.07s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:28<02:44, 164.11s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:12<00:00, 164.19s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:44<05:29, 164.59s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:28<02:44, 164.52s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:13<00:00, 164.38s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [49:30<2:53:29, 1487.09s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.93s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:27<02:43, 163.77s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:10<00:00, 163.58s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:42<05:25, 162.57s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:25<02:42, 162.77s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:09<00:00, 163.07s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:44<05:28, 164.46s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:28<02:44, 164.45s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:12<00:00, 164.28s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [1:14:04<2:28:18, 1483.11s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.67s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:27<02:43, 163.63s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:10<00:00, 163.66s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.81s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:28<02:43, 163.93s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:11<00:00, 163.99s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.65s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:26<02:43, 163.51s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:10<00:00, 163.37s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [1:38:38<2:03:21, 1480.39s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.57s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:26<02:43, 163.53s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:11<00:00, 163.84s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:45<05:30, 165.28s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:31<02:45, 165.60s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:16<00:00, 165.59s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.60s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:27<02:43, 163.69s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:11<00:00, 163.77s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [2:03:19<1:38:41, 1480.46s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:26, 163.49s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:26<02:43, 163.22s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:10<00:00, 163.47s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:26, 163.43s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:28<02:43, 163.85s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:12<00:00, 164.19s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:27, 163.90s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:27<02:43, 163.91s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:11<00:00, 163.78s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [2:27:54<1:13:56, 1478.94s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:45<05:30, 165.41s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [06:05<02:55, 175.90s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:52<00:00, 177.47s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:45<05:30, 165.34s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:31<02:45, 165.58s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:17<00:00, 165.69s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:43<05:26, 163.38s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:26<02:43, 163.21s/it]\u001b[A\n",
      "100%|██████████| 3/3 [08:23<00:00, 167.72s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [2:53:28<49:50, 1495.37s/it]  \n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:12<06:25, 192.85s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [06:30<03:14, 194.38s/it]\u001b[A\n",
      "100%|██████████| 3/3 [10:00<00:00, 200.16s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [02:58<05:57, 178.86s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [05:53<02:57, 177.65s/it]\u001b[A\n",
      "100%|██████████| 3/3 [09:00<00:00, 180.01s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:35<07:10, 215.17s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [06:41<03:26, 206.39s/it]\u001b[A\n",
      "100%|██████████| 3/3 [09:46<00:00, 195.55s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [3:22:16<26:05, 1565.25s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:18<06:36, 198.34s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [06:24<03:14, 194.80s/it]\u001b[A\n",
      "100%|██████████| 3/3 [09:51<00:00, 197.01s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:25<06:51, 205.51s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [06:49<03:24, 204.92s/it]\u001b[A\n",
      "100%|██████████| 3/3 [10:07<00:00, 202.61s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:30<07:00, 210.05s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [07:00<03:30, 210.18s/it]\u001b[A\n",
      "100%|██████████| 3/3 [10:31<00:00, 210.35s/it]\u001b[A\n",
      "100%|██████████| 9/9 [3:52:47<00:00, 1551.97s/it]\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "transform = ImageTransform(64, True)\n",
    "meta_file = \"../models/xgboost_internal_randomoversamplingdist.pkl\"\n",
    "with open(meta_file, 'rb') as file:\n",
    "    meta_model = pickle.load(file)\n",
    "\n",
    "alpha_vals = [x / 10 for x in range(1, 10)]\n",
    "alpha_scores = []\n",
    "for alpha in tqdm(alpha_vals):\n",
    "    fold_sum = 0\n",
    "    for i, (idxT,idxV) in enumerate(skf.split(np.arange(15))):\n",
    "        validation_ims = train.loc[train.tfrecord.isin(idxV)]\n",
    "        validation_ims.reset_index(drop=True, \n",
    "                                   inplace=True)\n",
    "        \n",
    "        X_valid = MelanomaDataset(\"../data/internal/train\", \n",
    "                                        validation_ims, \n",
    "                                        transform=transform, \n",
    "                                        phase='valid')\n",
    "        \n",
    "        net = load_model('resnet18', 2)\n",
    "        net.load_state_dict(\n",
    "            torch.load(\n",
    "                f\"../models/state_dict_resnet18_{i+1}.pt\", \n",
    "                map_location='cpu'))\n",
    "        \n",
    "        validation_meta = X_train.loc[train.tfrecord.isin(idxV)]\n",
    "        net_predictions = pd.DataFrame()\n",
    "\n",
    "        net_predictions = predict(X_valid, 128, net, 3, net_predictions, \"cpu\")\n",
    "        net_predictions = net_predictions.mean(axis=1)\n",
    "        \n",
    "        meta_preds = meta_model.predict_proba(validation_meta)[:, 1]\n",
    "        \n",
    "        preds = alpha * meta_preds + (1 - alpha) * net_predictions\n",
    "        fold_sum += roc_auc_score(y_true=validation_ims['target'], y_score=preds)\n",
    "    \n",
    "    alpha_scores.append(fold_sum / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8741562633061227,\n",
       " 0.882168477494396,\n",
       " 0.8857577326872245,\n",
       " 0.8862797408211801,\n",
       " 0.8840812210190078,\n",
       " 0.879645277270772,\n",
       " 0.8728993626479503,\n",
       " 0.86422148133741,\n",
       " 0.8541842695875159]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_max_idx = alpha_scores.index(max(alpha_scores))\n",
    "best_alpha = alpha_vals[alpha_max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the ensemble which performed best on the validation sets averaged over 3 folds used 40% of the tabular result and 60% of the resnet.\n",
    "\n",
    "Now let's get the predictions for this ensemble on the test set and see how it does on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:48<00:00, 56.13s/it]\n",
      "100%|██████████| 3/3 [02:41<00:00, 53.98s/it]\n",
      "100%|██████████| 3/3 [02:46<00:00, 55.52s/it]\n"
     ]
    }
   ],
   "source": [
    "meta_preds = meta_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_ims = MelanomaDataset(\"../data/internal/test\", test, transform=transform, phase='test')\n",
    "net_predictions = pd.DataFrame()\n",
    "\n",
    "for i in range(3):        \n",
    "    net = load_model('resnet18', 2)\n",
    "    net.load_state_dict(\n",
    "        torch.load(\n",
    "            f\"../models/state_dict_resnet18_{i+1}.pt\", \n",
    "            map_location='cpu'))\n",
    "\n",
    "    for _ in tqdm(range(3)):\n",
    "        net_preds = predict(test_ims, 128, net, \"cpu\")\n",
    "        net_preds = pd.DataFrame(torch.softmax(net_preds, 1)[:, 1].numpy())\n",
    "        net_predictions = pd.concat([net_predictions, net_preds], axis=1)\n",
    "net_predictions = net_predictions.mean(axis=1)\n",
    "\n",
    "preds = best_alpha * meta_preds + (1 - best_alpha) * net_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.023906\n",
       "1        0.009402\n",
       "2        0.016432\n",
       "3        0.008127\n",
       "4        0.101575\n",
       "           ...   \n",
       "10977    0.130427\n",
       "10978    0.413212\n",
       "10979    0.477556\n",
       "10980    0.025919\n",
       "10981    0.139902\n",
       "Length: 10982, dtype: float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-cd72ee00de5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../submissions/submission_ensemble_resnet_tabular_alpha0.4.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"total time: {round(time.time() - t, 4)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('../data/internal/sample_submission.csv')\n",
    "sub['target'] = preds\n",
    "sub.to_csv(f\"../submissions/submission_ensemble_resnet_tabular_alpha0.4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission scored 0.9035 on the public leaderboard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
